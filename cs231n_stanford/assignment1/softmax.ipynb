{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1179.940667\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** *Fill this in*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 729.330196 analytic: 729.330161, relative error: 2.406963e-08\n",
      "numerical: -822.267561 analytic: -822.267533, relative error: 1.694506e-08\n",
      "numerical: 453.593242 analytic: 453.593266, relative error: 2.645281e-08\n",
      "numerical: -650.120565 analytic: -650.120600, relative error: 2.698498e-08\n",
      "numerical: 785.375045 analytic: 785.375021, relative error: 1.501183e-08\n",
      "numerical: 516.948518 analytic: 516.948532, relative error: 1.376260e-08\n",
      "numerical: -2018.749070 analytic: -2018.749077, relative error: 1.777794e-09\n",
      "numerical: -1325.279007 analytic: -1325.278978, relative error: 1.095389e-08\n",
      "numerical: 604.029329 analytic: 604.029266, relative error: 5.154960e-08\n",
      "numerical: 764.132899 analytic: 764.132818, relative error: 5.301129e-08\n",
      "numerical: -206.481542 analytic: -206.481548, relative error: 1.224952e-08\n",
      "numerical: 260.821234 analytic: 260.821210, relative error: 4.658363e-08\n",
      "numerical: -708.453907 analytic: -708.453968, relative error: 4.263200e-08\n",
      "numerical: -269.880181 analytic: -269.880224, relative error: 8.065425e-08\n",
      "numerical: 461.705623 analytic: 461.705631, relative error: 8.827262e-09\n",
      "numerical: 353.148000 analytic: 353.147923, relative error: 1.096105e-07\n",
      "numerical: 173.907913 analytic: 173.907870, relative error: 1.246666e-07\n",
      "numerical: 430.724647 analytic: 430.724601, relative error: 5.409856e-08\n",
      "numerical: 45.040569 analytic: 45.040496, relative error: 8.086619e-07\n",
      "numerical: -2103.513288 analytic: -2103.513235, relative error: 1.260364e-08\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 1.179941e+03 computed in 0.077042s\n",
      "vectorized loss: 2.359881e+00 computed in 0.006181s\n",
      "Loss difference: 1177.580786\n",
      "Gradient difference: 164058.238224\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "(3073, 10)\n",
      "10\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "loss = 0.0\n",
    "dW = np.zeros_like(W)\n",
    "num_classes = W.shape[1]\n",
    "num_train = X_dev.shape[0]\n",
    "print(dW)\n",
    "print(dW.shape)\n",
    "print(num_classes)\n",
    "print(num_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 10)\n",
      "[[-0.0544169   0.07602815 -0.2050445  ..., -0.3062025  -0.23303242\n",
      "   0.03229881]\n",
      " [-0.3637381  -0.28536441  0.45279466 ..., -0.36134567 -0.81103549\n",
      "  -0.1018324 ]\n",
      " [ 0.06934057 -0.45824711  0.01639659 ...,  0.17498083 -0.04381121\n",
      "   0.33124976]\n",
      " ..., \n",
      " [-0.21301064 -0.19937023 -0.23604092 ..., -0.41097278 -0.32849981\n",
      "   0.29357166]\n",
      " [ 0.42868076  0.09685238  0.28009359 ...,  0.60161593  0.06934941\n",
      "   0.00324997]\n",
      " [ 0.193847    0.34714942 -0.03852985 ..., -0.33441021  0.23773938\n",
      "  -0.245807  ]]\n"
     ]
    }
   ],
   "source": [
    "scores = X_dev.dot(W)\n",
    "print (scores.shape)\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9470372   1.07899295  0.81461107 ...,  0.73623752  0.79212789\n",
      "   1.03282608]\n",
      " [ 0.69507321  0.75174026  1.57270122 ...,  0.69673811  0.44439766\n",
      "   0.90318091]\n",
      " [ 1.07180117  0.63239118  1.01653175 ...,  1.19122339  0.95713464\n",
      "   1.39270759]\n",
      " ..., \n",
      " [ 0.80814754  0.81924652  0.78974836 ...,  0.66300498  0.72000306\n",
      "   1.34120929]\n",
      " [ 1.53523084  1.10169772  1.32325364 ...,  1.8250656   1.07181064\n",
      "   1.00325526]\n",
      " [ 1.21391054  1.41502814  0.96220299 ...,  0.71576011  1.26837859\n",
      "   0.78207315]]\n"
     ]
    }
   ],
   "source": [
    "scores = np.exp(scores)\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "[ 10.12440693   9.97675979  10.14167502  11.55285122   8.86635349\n",
      "   9.37343039   8.94427171  10.81509473  13.53834941  12.1040548\n",
      "  12.49273995  10.87628154  12.47979745  11.84122112  12.82914486\n",
      "   9.33399255  11.31866095   9.27063423  10.16522058  11.91998363\n",
      "  10.08474939  12.27114677   9.05655172  11.43011177  11.10169314\n",
      "  10.84124872  13.6430145   10.41058593  10.25988027   9.66018003\n",
      "   9.56452555  10.41789484  11.25372     11.43720217   9.96745119\n",
      "   8.85266548  12.35453025  12.83996953  10.1880503    9.81966929\n",
      "  11.03671155  11.09679769  10.16730535  10.47059251  10.7740201\n",
      "   9.95216835  10.54387056   9.93934558  10.66179418  11.10332083\n",
      "   9.42566583  10.08654581  10.11009935  10.76857224   9.60533532\n",
      "  10.21574992   8.77452179  12.12077809  12.18912377  10.27895394\n",
      "  12.19084641  11.13077292   9.22829649   9.28935562   9.92507216\n",
      "  11.39330929  10.88846554  10.3453253   11.42830753  10.72206789\n",
      "  10.55155384  10.30174703  11.42966412  10.27733916   9.64336606\n",
      "  10.87968061   8.9052633   13.91549635  11.11314605   8.74205467\n",
      "  11.8876272    9.20839258   8.93319397   9.6236651   12.27566638\n",
      "  10.1087106    8.56038125  11.56422518  12.21395789  12.43857946\n",
      "  11.39636479  11.87404976  12.21673536   9.04398271  11.42959703\n",
      "   9.17280228  10.91560966   9.7094183   11.0702454   12.14148206\n",
      "  11.63164306  10.7218211   10.716169    11.26184172   9.34477743\n",
      "   9.12062079   7.65812967  12.41221351   9.86878726  11.04167635\n",
      "   9.0006139    8.88027138  10.89707155  11.53203061  10.07511942\n",
      "  10.52640114  11.09095612   8.89491295   8.79006488  10.8208271\n",
      "   8.10101139  10.66424248  11.10159051   9.27654883  11.51833745\n",
      "  10.4958475   10.26925545  11.35152564  11.4218558    8.90857288\n",
      "  10.22627575  11.20584069  12.22814885   9.8153741   11.38800884\n",
      "  11.92852875  11.59729615  12.56567056   9.4576749   11.37972609\n",
      "   9.09482657   8.25107662   9.48017373  10.34081231  12.78932117\n",
      "  10.02235552   9.34668746   9.99628525  10.08123688   9.63145327\n",
      "  13.45952921  11.06504152   8.6486782    8.65928542   9.46344291\n",
      "   9.97853645   9.43331074  10.32125297  11.5937409   12.04392931\n",
      "   9.99977388  10.17719939  10.41495758  11.43634979   9.55762325\n",
      "  10.95492441  13.05189951  10.24237098  10.57812015  11.65529684\n",
      "   8.7648708   10.46598453  10.61960454   9.86468649  10.3308339\n",
      "  11.33732774  12.91921077  10.85526598   9.9647864   12.3407092\n",
      "   9.93952785   9.25263458  12.87860636  11.70350877  12.17638328\n",
      "  15.65832512  10.58168029  10.64435857   8.93735947   9.99026607\n",
      "  11.68405404  10.84401266  10.88920167  10.3778886   10.15628226\n",
      "   8.44555439  12.55866967  11.66128111  10.77268145  11.31623713\n",
      "  11.20034459  10.35974434  10.89220363  10.42135903   9.50391239\n",
      "   8.7423389    8.76892525  11.315272    11.02930529  10.72059407\n",
      "  10.7902072   10.11111171  12.32143156  10.62237101  10.16620106\n",
      "  10.62346846  10.08146267  10.25322142   9.52811313  10.93383806\n",
      "  11.13281241  10.12716311  10.83452073   9.19606597  13.10175067\n",
      "  11.16107251  12.00225426  14.19154227  11.11593976  10.73528577\n",
      "   9.15651674  11.84389963  11.29984561   9.86495264  12.96458681\n",
      "   9.74723348   9.8615568    7.8533903   10.13634902   8.68965493\n",
      "  11.7167339   11.77234818   8.81626726  10.75297673  11.8629636\n",
      "   9.49973544  10.51538124  10.23762695   9.0942507   12.90037798\n",
      "  10.94358915  10.0658899   11.507289     8.51422476  10.31839901\n",
      "  12.17125759  11.71462126  11.20635826  11.11225427  11.80366293\n",
      "  11.24940138   9.20487927   8.74535345  11.05758961  13.01933057\n",
      "  12.32486381  11.21260653  10.4579855    9.06409741  10.51562194\n",
      "  12.8208174   10.19013684  10.93904585   9.21058724   9.45698948\n",
      "   9.97253241  12.08733951  10.00376742  10.49459893   9.54893481\n",
      "   8.50047906   9.63189726   9.88826234   9.71245868  10.39807384\n",
      "   9.74108529   8.54048039  10.45434873   8.78452183  11.64947794\n",
      "   9.7013228   12.7109894   10.61950583   9.52731071  10.75703179\n",
      "  10.25320921  10.57074845   9.06772255  10.28950948  11.7113529\n",
      "   9.07990199  11.29293963  12.3764414   10.78803094  11.52588336\n",
      "   9.92768675  10.97766033   9.59285984  11.15546793  11.30306781\n",
      "   9.37174523  10.65999438  10.11440957   9.75182971  11.6946582\n",
      "  11.93155424   9.26381547   8.90986387  11.16342021   9.2547488\n",
      "  11.70292014  12.34418331   9.91722869  12.51457043  12.51826603\n",
      "   8.70711136  11.90956881   9.90126155  10.17349582  13.19223169\n",
      "   8.15928323  10.84202736   9.78632433  10.32416226   8.32977727  10.62297\n",
      "  10.65681505   9.58058982   8.28963107  12.05510378  10.43717675\n",
      "  12.42113679  10.66167733  10.78619675   9.30408348  10.31872333\n",
      "  12.24587132  10.04565655  11.94293031  10.39952216  10.59215681\n",
      "  11.69046677  10.21006463  10.59565178  11.43930058  10.928051\n",
      "   9.99575207  10.54249867  11.27753794   9.84914996   9.77719957\n",
      "  10.78641054   9.27519423  10.84437736   8.5878407    9.89874612\n",
      "   9.99950837  12.71002945  10.09591032  11.61559701   8.8488735\n",
      "  11.04644624   8.81093076  11.85912328  11.81548651   9.51274302\n",
      "  10.12732742  11.30694939  11.93257203  10.49987697   9.42980433\n",
      "   8.0774978   10.18463047  11.49208439  11.20519868   8.93684503\n",
      "  10.80557467   9.9470175   11.13744789   9.86868301  12.12385569\n",
      "  13.98986743  13.08149296  11.37867969   9.32081982  11.32332354\n",
      "   9.70753433  11.04489645  10.35793087   9.57051289  10.98068639\n",
      "  10.58210015   9.43073729  10.83530666   9.07007943  11.44882579\n",
      "  11.25985598  12.6853721   10.88185458  10.13811855   9.68247589\n",
      "  12.18069151  11.8577412    9.18722493  10.54805958   8.39835855\n",
      "  10.57883882  10.29634359  12.18977374  11.67019943   9.13081737\n",
      "  12.49299172  11.84674695  11.37128683   9.12687721  10.44295212\n",
      "  12.03322697  11.00451371  11.05284132   9.88050726  10.12177062\n",
      "  13.04049297  11.55486158  10.74661142  11.053886     9.14834388\n",
      "  10.05633903  10.81782198  11.34170977  10.36433126  11.99645161\n",
      "  10.63810049  10.92975187  11.20399756  10.37899499   9.92134662\n",
      "  12.52556764   8.32525204  11.21293025  10.67553319  10.63297074\n",
      "  11.09252902   8.81127024  10.11304786  12.15750397   9.95317875\n",
      "  10.30266618  10.92888587   9.10324586   9.98648634  10.78010612\n",
      "   8.79495188   9.05230039  11.18432325   9.00803758  12.16701326\n",
      "  11.99496687  10.45343683   8.48074052  12.64976019   8.84838527\n",
      "   8.35284003  10.61966826   8.08498254   9.98867381  10.49049295\n",
      "  12.99663389  10.31855764  11.43298865   9.84254438  11.99382763\n",
      "  11.37762158  12.60568163  11.82589277   9.46687468  13.28628763\n",
      "   8.98045967  10.60684016   8.63467897  10.36589539   9.67047283\n",
      "  11.87698835  11.41868433  12.46862424   9.37413383  11.93976461\n",
      "  12.27637333   9.71669076  12.24017578   9.94000508]\n"
     ]
    }
   ],
   "source": [
    "scores_sums = np.sum(scores, axis=1)\n",
    "print (scores_sums.shape)\n",
    "print (scores_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 1, 2, 7, 5, 3, 0, 3, 7, 7, 7, 3, 1, 0, 4, 1, 6, 5, 2, 4, 3, 2, 0,\n",
       "       4, 2, 6, 0, 8, 3, 3, 7, 3, 6, 4, 8, 9, 0, 9, 3, 8, 2, 6, 9, 3, 2, 9,\n",
       "       2, 7, 7, 8, 8, 2, 9, 3, 8, 6, 8, 1, 1, 7, 6, 6, 8, 1, 5, 9, 0, 1, 7,\n",
       "       1, 4, 7, 5, 5, 5, 7, 1, 2, 5, 8, 3, 1, 0, 3, 9, 0, 8, 1, 4, 7, 4, 0,\n",
       "       7, 2, 2, 8, 2, 2, 5, 4, 0, 1, 0, 1, 9, 2, 0, 6, 6, 2, 2, 1, 7, 3, 8,\n",
       "       4, 4, 1, 0, 8, 5, 9, 1, 5, 7, 1, 1, 9, 9, 5, 2, 7, 6, 9, 8, 5, 6, 5,\n",
       "       8, 7, 6, 8, 3, 4, 5, 4, 9, 7, 8, 9, 7, 5, 5, 5, 3, 4, 2, 4, 5, 4, 1,\n",
       "       3, 7, 6, 8, 5, 6, 4, 2, 2, 3, 5, 7, 0, 8, 7, 2, 0, 8, 4, 8, 6, 5, 0,\n",
       "       9, 7, 5, 9, 3, 3, 3, 0, 5, 7, 4, 2, 9, 1, 2, 1, 1, 0, 9, 8, 1, 4, 0,\n",
       "       5, 3, 3, 7, 9, 1, 2, 4, 1, 9, 2, 0, 4, 1, 1, 0, 5, 6, 1, 7, 3, 3, 4,\n",
       "       8, 7, 9, 2, 3, 5, 3, 1, 9, 8, 4, 8, 0, 7, 4, 0, 6, 7, 2, 4, 1, 7, 3,\n",
       "       0, 4, 5, 4, 7, 4, 8, 3, 8, 4, 1, 9, 2, 5, 2, 8, 1, 5, 3, 5, 3, 7, 2,\n",
       "       3, 4, 4, 8, 5, 7, 1, 8, 8, 9, 8, 7, 2, 4, 9, 4, 5, 2, 5, 5, 6, 8, 1,\n",
       "       8, 2, 3, 7, 0, 7, 3, 9, 0, 6, 6, 9, 1, 3, 6, 0, 6, 8, 0, 4, 5, 4, 5,\n",
       "       6, 6, 6, 2, 4, 9, 7, 5, 9, 9, 8, 2, 1, 0, 9, 5, 0, 7, 6, 1, 6, 6, 5,\n",
       "       0, 6, 8, 6, 5, 1, 1, 5, 3, 0, 1, 2, 7, 6, 4, 0, 0, 7, 1, 8, 0, 3, 6,\n",
       "       7, 6, 8, 2, 3, 2, 7, 8, 5, 5, 9, 6, 8, 8, 7, 1, 4, 3, 5, 6, 1, 0, 7,\n",
       "       3, 4, 6, 3, 7, 0, 0, 6, 3, 4, 1, 9, 2, 4, 9, 4, 9, 6, 6, 8, 3, 3, 0,\n",
       "       3, 7, 5, 8, 4, 3, 5, 4, 3, 2, 8, 3, 3, 1, 5, 0, 0, 6, 8, 9, 6, 1, 8,\n",
       "       7, 2, 9, 6, 2, 6, 7, 6, 8, 6, 0, 7, 1, 5, 5, 7, 7, 7, 2, 9, 1, 0, 9,\n",
       "       6, 1, 5, 3, 8, 6, 1, 9, 8, 2, 5, 3, 5, 7, 2, 8, 0, 7, 5, 3, 1, 9, 4,\n",
       "       8, 7, 7, 7, 1, 8, 1, 3, 0, 1, 7, 3, 8, 6, 3, 4, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.73623752  0.75174026  1.01653175  1.18271886  1.04156532  0.75506583\n",
      "  0.47215318  0.84470219  1.99607364  1.07145313  1.11344941  0.68182815\n",
      "  2.12776067  1.29628799  0.91909309  1.13868293  0.8193057   0.55138638\n",
      "  1.31889692  1.21078817  0.87570827  1.24247968  0.92343229  1.50819758\n",
      "  1.55490853  0.98039244  1.61028419  0.73318286  0.93258305  0.82637429\n",
      "  1.1305814   1.01067252  0.60511651  2.21580023  0.81668503  0.9647501\n",
      "  1.70649514  0.7604527   1.01202263  0.72874241  0.88750756  1.22256502\n",
      "  0.72329973  0.7513649   1.1985244   0.63131329  0.83210522  0.86151438\n",
      "  1.35366174  1.29916117  0.93855277  0.96275978  1.12002219  1.19930912\n",
      "  1.31096733  1.29986488  0.81627729  1.54620855  1.12693077  0.85269699\n",
      "  1.83567906  1.17027655  1.06382057  1.08994885  0.89232141  0.79221116\n",
      "  1.29538862  0.90810258  1.11417748  0.98379281  0.75232102  1.57315626\n",
      "  1.49607944  0.74763648  1.21056176  0.97712167  0.64308868  1.20075861\n",
      "  1.39649299  1.05707377  1.07614572  0.82027221  0.75863241  0.85769375\n",
      "  0.70937766  0.89066897  1.10990476  1.34934477  0.84262655  1.23553015\n",
      "  1.20264977  1.09732421  0.84664005  0.4485528   0.85045826  0.76306097\n",
      "  0.87075794  1.66501538  0.74767541  0.72605067  0.95752881  1.08899521\n",
      "  0.86112476  1.1975791   1.17307564  0.91938262  0.56307501  1.003581\n",
      "  1.31826742  1.04753199  0.55201164  1.08012887  0.78802069  0.96921291\n",
      "  1.12433373  0.99099457  0.8939264   0.77154233  0.8101181   1.48077735\n",
      "  0.85002103  0.66453465  0.64410014  0.99911077  1.37442446  1.07879386\n",
      "  1.07908694  0.75958586  0.81731927  1.0359363   0.76412922  1.01596832\n",
      "  1.15930505  0.63478519  1.12895657  0.96818971  1.00668624  1.22089412\n",
      "  0.8181763   2.2284982   0.59585047  0.94936638  0.79456586  0.83892937\n",
      "  1.53679949  0.59370042  0.95911136  0.83832494  1.0786085   0.93288744\n",
      "  0.85017116  1.24497482  0.83013537  0.48245877  0.68991087  1.12259963\n",
      "  0.98432503  0.82730499  0.61289673  1.42683736  0.70562582  0.77179845\n",
      "  1.36090117  1.12862987  0.85409292  0.8394585   1.9679137   1.43176812\n",
      "  1.0030576   1.09790008  1.32219772  0.91742319  1.13420844  0.94241943\n",
      "  1.0515883   1.67963458  1.13916468  1.05264709  1.45484639  1.38997146\n",
      "  1.21946358  0.63474293  1.22716165  1.69391767  0.84440287  2.3375274\n",
      "  1.0728355   0.73209831  1.204545    0.91585793  0.78856178  1.10730943\n",
      "  1.09061998  0.87142726  1.00099554  1.0124638   0.90855802  2.12671569\n",
      "  0.61570706  1.131082    1.12443973  1.5827439   0.75715527  1.00067678\n",
      "  0.50946028  0.53344558  0.6672282   0.78674354  0.84968986  0.69432259\n",
      "  0.80280486  0.66682145  0.62255191  1.16898367  0.97434636  1.0938873\n",
      "  1.3343013   1.47677041  0.960046    1.14088504  0.67078284  1.22764382\n",
      "  1.18104068  0.81039324  2.06093789  1.13864043  1.6134775   1.14963969\n",
      "  1.18376993  0.86979577  0.7896473   1.66897973  0.97729838  0.73625891\n",
      "  0.4454648   0.77356353  1.17253391  0.84558458  1.18022295  0.90701734\n",
      "  1.02505996  0.67973941  1.0071543   1.10792325  1.56342977  0.72921529\n",
      "  1.07447924  0.71147066  0.38982717  1.55548785  1.22786394  0.96376634\n",
      "  1.23063003  0.80653448  0.99163354  0.70547669  0.950676    1.76617864\n",
      "  1.34153968  1.24618048  1.11696544  1.13114949  0.99223761  1.36077843\n",
      "  1.15924503  1.33220262  0.94635772  1.52633697  0.89213671  0.49942311\n",
      "  1.27153969  0.92710305  1.29355453  1.55542728  0.91328115  0.90126819\n",
      "  1.20416306  1.44976614  1.25826253  1.02811657  0.45349507  0.63838519\n",
      "  1.20586361  0.90587328  1.44198332  0.84581398  0.90607459  1.06378187\n",
      "  0.3986493   1.14524058  1.87018766  1.29787441  0.79649802  0.86963723\n",
      "  0.70590906  0.9601497   1.14402301  0.74440573  1.08036485  1.05091349\n",
      "  0.40860891  0.95624332  2.00465367  1.0656867   1.16844493  1.42198933\n",
      "  1.24645452  1.0772384   1.08404318  0.72695679  1.26733855  1.04940321\n",
      "  1.25743977  1.10772531  0.97569918  1.18474772  0.88531606  0.70686748\n",
      "  1.16701956  0.83499198  1.34682827  1.21788535  1.22627103  1.79314522\n",
      "  2.19419469  0.65868884  1.16022149  1.55146704  1.14504852  1.7278036\n",
      "  0.8431709   0.98225329  0.67817908  0.80327297  0.45925684  0.86385017\n",
      "  0.89844128  1.03011324  0.82734677  1.62009255  0.61331072  1.25063654\n",
      "  0.78799056  0.88768622  0.68596321  1.06206857  1.45696106  0.90838545\n",
      "  2.31207897  1.0432091   1.06459387  1.00282816  0.7665363   1.17053779\n",
      "  1.43519117  0.53284929  0.90499006  0.85479606  1.01435191  0.95615921\n",
      "  0.7761304   1.2080596   0.75062362  0.62996241  1.00493777  0.92251451\n",
      "  0.85038821  0.86938786  1.06816784  0.86153908  0.80473883  1.06795296\n",
      "  0.98309003  0.87288054  1.69484086  1.19183441  0.99160295  0.71984246\n",
      "  0.63089455  0.81525588  0.85436677  1.05067677  1.15611709  0.90151778\n",
      "  1.19912441  0.92629284  0.74640449  1.05397316  1.05085723  0.52068083\n",
      "  0.96798826  0.66238866  0.98666785  1.4161268   1.50502807  1.85285974\n",
      "  0.79604613  1.19976207  0.93646004  1.12359776  0.90287832  1.20942134\n",
      "  1.49853505  0.98328323  0.88348239  1.01302539  1.50699467  0.9766165\n",
      "  1.1830372   0.96148723  1.07216356  1.22301279  1.04851102  1.02322705\n",
      "  1.44161955  0.8896136   1.02676053  1.06316063  0.84303285  1.14752771\n",
      "  0.80421029  0.79800597  0.99376707  1.54210972  0.82920036  0.74341607\n",
      "  1.05584894  1.36072175  1.12698284  0.80861549  0.97052247  0.71604885\n",
      "  1.16960702  1.31968095  1.15836524  1.04193997  1.07829705  0.96471498\n",
      "  1.19359527  0.48570999  1.40757418  0.89732883  1.31260581  1.19821859\n",
      "  1.14250598  0.66313011  0.78390138  0.65928096  2.20941692  0.53874687\n",
      "  1.2652987   1.01039919  0.46779682  0.9236912   1.64826947  0.6442523\n",
      "  1.00086243  1.02029018  0.66481679  0.90297929  1.23346877  1.15320145\n",
      "  0.95274653  1.05812827  0.99469514  1.38922997  1.04593216  0.912409\n",
      "  0.56590549  1.87390264  0.67601587  1.05136817  0.61304642  0.49441112\n",
      "  0.98984597  0.9215546   1.77630394  2.00040605  0.87993277  0.80791177\n",
      "  0.90752521  0.73936471  1.14354913  1.26181028  0.86977515  2.18828405\n",
      "  0.58144981  1.52706194  0.81946822  0.87888298  1.06770184  0.73076176\n",
      "  0.88281091  1.44732579  0.9724817   1.5504194   0.69119875  1.1251142\n",
      "  1.2553902   1.01156115]\n"
     ]
    }
   ],
   "source": [
    "cors = scores[range(num_train), y_dev]\n",
    "print (cors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print (cors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "[ 0.07271908  0.07534914  0.10023312  0.10237463  0.11747392  0.08055384\n",
      "  0.05278833  0.078104    0.14743848  0.08852018  0.08912772  0.06268945\n",
      "  0.17049641  0.10947249  0.07164103  0.12199313  0.07238539  0.05947666\n",
      "  0.12974602  0.10157633  0.08683491  0.10125212  0.1019629   0.1319495\n",
      "  0.14006049  0.09043169  0.11802994  0.07042667  0.09089609  0.0855444\n",
      "  0.1182057   0.09701312  0.05377035  0.19373621  0.08193519  0.10897849\n",
      "  0.13812708  0.05922543  0.09933428  0.07421252  0.08041413  0.11017278\n",
      "  0.07113977  0.07175954  0.11124208  0.06343475  0.07891838  0.08667717\n",
      "  0.12696378  0.11700654  0.09957416  0.0954499   0.11078251  0.11137123\n",
      "  0.13648324  0.12724126  0.09302812  0.12756677  0.0924538   0.08295562\n",
      "  0.15057847  0.10513884  0.11527811  0.1173331   0.08990579  0.06953302\n",
      "  0.11896889  0.08777903  0.09749278  0.09175402  0.07129955  0.15270772\n",
      "  0.13089444  0.07274611  0.12553311  0.08981161  0.07221445  0.08628931\n",
      "  0.12566135  0.12091823  0.09052654  0.08907876  0.08492286  0.0891234\n",
      "  0.0577873   0.08810906  0.129656    0.11668268  0.06898882  0.09933049\n",
      "  0.10552925  0.09241364  0.06930166  0.04959682  0.07440842  0.08318733\n",
      "  0.07977181  0.17148457  0.06753919  0.05979918  0.08232103  0.10156812\n",
      "  0.08035752  0.10633954  0.12553275  0.10080264  0.07352644  0.08085431\n",
      "  0.13357947  0.09487074  0.06133044  0.12163242  0.0723149   0.08404529\n",
      "  0.11159508  0.09414372  0.08059958  0.08673973  0.09216293  0.13684512\n",
      "  0.10492777  0.06231429  0.05801873  0.10770285  0.1193249   0.10278292\n",
      "  0.10507937  0.06691487  0.07155748  0.11628533  0.07472214  0.09066418\n",
      "  0.09480626  0.06467254  0.09913555  0.0811659   0.08680353  0.09716108\n",
      "  0.08650924  0.19583057  0.06551532  0.1150597   0.08381343  0.081128\n",
      "  0.12016271  0.05923761  0.10261511  0.08386365  0.10699168  0.09685843\n",
      "  0.063165    0.11251425  0.09598407  0.05571577  0.07290273  0.11250143\n",
      "  0.10434566  0.08015548  0.05286445  0.11846942  0.07056418  0.07583603\n",
      "  0.13066795  0.09868795  0.08936248  0.07662842  0.15077604  0.13978874\n",
      "  0.09482381  0.09419752  0.15085194  0.08765761  0.10680327  0.09553466\n",
      "  0.10179123  0.14815084  0.08817603  0.0969711   0.14599875  0.11263303\n",
      "  0.12268828  0.06860132  0.09528684  0.14473588  0.06934759  0.14928336\n",
      "  0.10138612  0.06877806  0.13477639  0.09167503  0.06749043  0.10211252\n",
      "  0.1001561   0.08396961  0.09855925  0.11988127  0.07234508  0.1823741\n",
      "  0.05715448  0.09995213  0.10039332  0.15277828  0.06951351  0.09602172\n",
      "  0.05360532  0.06101863  0.07609008  0.06952935  0.07703929  0.06476531\n",
      "  0.07440125  0.06594937  0.05052594  0.11004922  0.09584174  0.10296894\n",
      "  0.13235196  0.1440299   0.1007593   0.10434442  0.06025278  0.12122287\n",
      "  0.10900719  0.0881239   0.15730248  0.10201891  0.1344312   0.08100879\n",
      "  0.10649301  0.08102214  0.08623883  0.14091471  0.08648776  0.0746338\n",
      "  0.03436012  0.07936237  0.11889947  0.10767128  0.11643472  0.10437898\n",
      "  0.08748683  0.05774034  0.11423818  0.1030341   0.13179083  0.07676164\n",
      "  0.10218167  0.06949566  0.04286523  0.12057692  0.11219938  0.09574577\n",
      "  0.10694352  0.09472788  0.09610343  0.05796251  0.08115294  0.15760505\n",
      "  0.12072615  0.10557574  0.0992911   0.12288586  0.11345883  0.12306284\n",
      "  0.08904029  0.10809066  0.08440122  0.14594942  0.09842532  0.04749344\n",
      "  0.09917774  0.09098043  0.11825113  0.16887384  0.09657208  0.09037506\n",
      "  0.09962184  0.14492202  0.1198962   0.10766819  0.05334935  0.06627824\n",
      "  0.12194899  0.0932692   0.13867793  0.08682954  0.10609176  0.10175496\n",
      "  0.04538088  0.09830832  0.19277656  0.10210648  0.0750033   0.09127835\n",
      "  0.06562303  0.09364382  0.10822536  0.08209401  0.10499673  0.08973459\n",
      "  0.04500147  0.08467621  0.16197335  0.09878417  0.10137574  0.14323471\n",
      "  0.11354464  0.11229586  0.09717595  0.064315    0.13522973  0.09844313\n",
      "  0.12432162  0.11359154  0.08343118  0.09929534  0.09556711  0.07933539\n",
      "  0.10453961  0.09022308  0.1150848   0.09866067  0.12365057  0.1432846\n",
      "  0.17527944  0.07564953  0.09741927  0.15669388  0.11255212  0.13097129\n",
      "  0.10333884  0.09059683  0.06929865  0.07780515  0.05513435  0.08131908\n",
      "  0.08430673  0.10752086  0.09980502  0.13439059  0.05876213  0.10068616\n",
      "  0.07390869  0.08229835  0.07372711  0.10292635  0.1189757   0.09042569\n",
      "  0.19359394  0.10031318  0.10050775  0.0857817   0.07507654  0.11047341\n",
      "  0.12546144  0.04875977  0.09053747  0.08108097  0.08994445  0.09708038\n",
      "  0.07938167  0.1119983   0.08092808  0.05809116  0.11701868  0.09319509\n",
      "  0.085043    0.06840172  0.10580203  0.07417088  0.09094252  0.09667842\n",
      "  0.11157618  0.07360414  0.14344233  0.1252882   0.09791359  0.06366372\n",
      "  0.05287163  0.07764433  0.09060281  0.13007454  0.11351586  0.07844685\n",
      "  0.10701501  0.10364875  0.06907587  0.10595871  0.0943535   0.05276092\n",
      "  0.07984162  0.04734774  0.07542471  0.1244544   0.16146949  0.16363215\n",
      "  0.08200292  0.10862592  0.09040995  0.11740204  0.08222421  0.11428935\n",
      "  0.15889903  0.09074808  0.09740625  0.08848291  0.13383783  0.07698761\n",
      "  0.10871651  0.09483882  0.11073238  0.10040586  0.08842418  0.11137499\n",
      "  0.13667154  0.10592708  0.09705796  0.10325613  0.06915902  0.09832974\n",
      "  0.08807648  0.06387629  0.08388523  0.13561435  0.09085258  0.07118831\n",
      "  0.08774445  0.12365124  0.10196318  0.08183947  0.09588465  0.05490965\n",
      "  0.10122207  0.12279973  0.10479258  0.11389383  0.10722561  0.0891783\n",
      "  0.10523945  0.04686361  0.11733254  0.08435048  0.12009475  0.10694563\n",
      "  0.11007867  0.06683872  0.0625841   0.07919051  0.19704189  0.05046557\n",
      "  0.11899767  0.09108826  0.05309074  0.09133658  0.13557631  0.0647283\n",
      "  0.09714596  0.0933572   0.07303074  0.09042012  0.11442084  0.13112084\n",
      "  0.10524911  0.09460816  0.11042307  0.11418003  0.08719759  0.08728316\n",
      "  0.06672831  0.1481374   0.07639991  0.12586954  0.05772746  0.06115179\n",
      "  0.09909684  0.08784664  0.13667415  0.19386489  0.07696437  0.08208363\n",
      "  0.07566602  0.06498412  0.09071696  0.10669894  0.09187564  0.16470244\n",
      "  0.06474611  0.14396954  0.09490431  0.08478602  0.11040844  0.06152753\n",
      "  0.07731284  0.11607742  0.10374097  0.12985343  0.05630317  0.11579191\n",
      "  0.10256309  0.10176666]\n"
     ]
    }
   ],
   "source": [
    "loss = cors / scores_sums\n",
    "print (loss.shape)\n",
    "print (loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.35988133577\n"
     ]
    }
   ],
   "source": [
    "loss = -np.sum(np.log(loss))/num_train + 0.000005 * np.sum(W*W)\n",
    "print (loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_sums.reshape(num_train, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09354002  0.10657345  0.08046013 ...,  0.07271908  0.07823944\n",
      "   0.10201349]\n",
      " [ 0.06966923  0.07534914  0.15763647 ...,  0.06983611  0.04454329\n",
      "   0.09052848]\n",
      " [ 0.10568285  0.06235569  0.10023312 ...,  0.11745825  0.09437639\n",
      "   0.1373252 ]\n",
      " ..., \n",
      " [ 0.08317107  0.08431333  0.0812775  ...,  0.06823362  0.07409962\n",
      "   0.13803149]\n",
      " [ 0.12542556  0.09000669  0.10810741 ...,  0.14910453  0.08756497\n",
      "   0.08196412]\n",
      " [ 0.12212373  0.14235688  0.09680106 ...,  0.07200802  0.12760341\n",
      "   0.07867935]]\n",
      "(500, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.07271908,  0.07534914,  0.10023312,  0.10237463,  0.11747392,\n",
       "        0.08055384,  0.05278833,  0.078104  ,  0.14743848,  0.08852018,\n",
       "        0.08912772,  0.06268945,  0.17049641,  0.10947249,  0.07164103,\n",
       "        0.12199313,  0.07238539,  0.05947666,  0.12974602,  0.10157633,\n",
       "        0.08683491,  0.10125212,  0.1019629 ,  0.1319495 ,  0.14006049,\n",
       "        0.09043169,  0.11802994,  0.07042667,  0.09089609,  0.0855444 ,\n",
       "        0.1182057 ,  0.09701312,  0.05377035,  0.19373621,  0.08193519,\n",
       "        0.10897849,  0.13812708,  0.05922543,  0.09933428,  0.07421252,\n",
       "        0.08041413,  0.11017278,  0.07113977,  0.07175954,  0.11124208,\n",
       "        0.06343475,  0.07891838,  0.08667717,  0.12696378,  0.11700654,\n",
       "        0.09957416,  0.0954499 ,  0.11078251,  0.11137123,  0.13648324,\n",
       "        0.12724126,  0.09302812,  0.12756677,  0.0924538 ,  0.08295562,\n",
       "        0.15057847,  0.10513884,  0.11527811,  0.1173331 ,  0.08990579,\n",
       "        0.06953302,  0.11896889,  0.08777903,  0.09749278,  0.09175402,\n",
       "        0.07129955,  0.15270772,  0.13089444,  0.07274611,  0.12553311,\n",
       "        0.08981161,  0.07221445,  0.08628931,  0.12566135,  0.12091823,\n",
       "        0.09052654,  0.08907876,  0.08492286,  0.0891234 ,  0.0577873 ,\n",
       "        0.08810906,  0.129656  ,  0.11668268,  0.06898882,  0.09933049,\n",
       "        0.10552925,  0.09241364,  0.06930166,  0.04959682,  0.07440842,\n",
       "        0.08318733,  0.07977181,  0.17148457,  0.06753919,  0.05979918,\n",
       "        0.08232103,  0.10156812,  0.08035752,  0.10633954,  0.12553275,\n",
       "        0.10080264,  0.07352644,  0.08085431,  0.13357947,  0.09487074,\n",
       "        0.06133044,  0.12163242,  0.0723149 ,  0.08404529,  0.11159508,\n",
       "        0.09414372,  0.08059958,  0.08673973,  0.09216293,  0.13684512,\n",
       "        0.10492777,  0.06231429,  0.05801873,  0.10770285,  0.1193249 ,\n",
       "        0.10278292,  0.10507937,  0.06691487,  0.07155748,  0.11628533,\n",
       "        0.07472214,  0.09066418,  0.09480626,  0.06467254,  0.09913555,\n",
       "        0.0811659 ,  0.08680353,  0.09716108,  0.08650924,  0.19583057,\n",
       "        0.06551532,  0.1150597 ,  0.08381343,  0.081128  ,  0.12016271,\n",
       "        0.05923761,  0.10261511,  0.08386365,  0.10699168,  0.09685843,\n",
       "        0.063165  ,  0.11251425,  0.09598407,  0.05571577,  0.07290273,\n",
       "        0.11250143,  0.10434566,  0.08015548,  0.05286445,  0.11846942,\n",
       "        0.07056418,  0.07583603,  0.13066795,  0.09868795,  0.08936248,\n",
       "        0.07662842,  0.15077604,  0.13978874,  0.09482381,  0.09419752,\n",
       "        0.15085194,  0.08765761,  0.10680327,  0.09553466,  0.10179123,\n",
       "        0.14815084,  0.08817603,  0.0969711 ,  0.14599875,  0.11263303,\n",
       "        0.12268828,  0.06860132,  0.09528684,  0.14473588,  0.06934759,\n",
       "        0.14928336,  0.10138612,  0.06877806,  0.13477639,  0.09167503,\n",
       "        0.06749043,  0.10211252,  0.1001561 ,  0.08396961,  0.09855925,\n",
       "        0.11988127,  0.07234508,  0.1823741 ,  0.05715448,  0.09995213,\n",
       "        0.10039332,  0.15277828,  0.06951351,  0.09602172,  0.05360532,\n",
       "        0.06101863,  0.07609008,  0.06952935,  0.07703929,  0.06476531,\n",
       "        0.07440125,  0.06594937,  0.05052594,  0.11004922,  0.09584174,\n",
       "        0.10296894,  0.13235196,  0.1440299 ,  0.1007593 ,  0.10434442,\n",
       "        0.06025278,  0.12122287,  0.10900719,  0.0881239 ,  0.15730248,\n",
       "        0.10201891,  0.1344312 ,  0.08100879,  0.10649301,  0.08102214,\n",
       "        0.08623883,  0.14091471,  0.08648776,  0.0746338 ,  0.03436012,\n",
       "        0.07936237,  0.11889947,  0.10767128,  0.11643472,  0.10437898,\n",
       "        0.08748683,  0.05774034,  0.11423818,  0.1030341 ,  0.13179083,\n",
       "        0.07676164,  0.10218167,  0.06949566,  0.04286523,  0.12057692,\n",
       "        0.11219938,  0.09574577,  0.10694352,  0.09472788,  0.09610343,\n",
       "        0.05796251,  0.08115294,  0.15760505,  0.12072615,  0.10557574,\n",
       "        0.0992911 ,  0.12288586,  0.11345883,  0.12306284,  0.08904029,\n",
       "        0.10809066,  0.08440122,  0.14594942,  0.09842532,  0.04749344,\n",
       "        0.09917774,  0.09098043,  0.11825113,  0.16887384,  0.09657208,\n",
       "        0.09037506,  0.09962184,  0.14492202,  0.1198962 ,  0.10766819,\n",
       "        0.05334935,  0.06627824,  0.12194899,  0.0932692 ,  0.13867793,\n",
       "        0.08682954,  0.10609176,  0.10175496,  0.04538088,  0.09830832,\n",
       "        0.19277656,  0.10210648,  0.0750033 ,  0.09127835,  0.06562303,\n",
       "        0.09364382,  0.10822536,  0.08209401,  0.10499673,  0.08973459,\n",
       "        0.04500147,  0.08467621,  0.16197335,  0.09878417,  0.10137574,\n",
       "        0.14323471,  0.11354464,  0.11229586,  0.09717595,  0.064315  ,\n",
       "        0.13522973,  0.09844313,  0.12432162,  0.11359154,  0.08343118,\n",
       "        0.09929534,  0.09556711,  0.07933539,  0.10453961,  0.09022308,\n",
       "        0.1150848 ,  0.09866067,  0.12365057,  0.1432846 ,  0.17527944,\n",
       "        0.07564953,  0.09741927,  0.15669388,  0.11255212,  0.13097129,\n",
       "        0.10333884,  0.09059683,  0.06929865,  0.07780515,  0.05513435,\n",
       "        0.08131908,  0.08430673,  0.10752086,  0.09980502,  0.13439059,\n",
       "        0.05876213,  0.10068616,  0.07390869,  0.08229835,  0.07372711,\n",
       "        0.10292635,  0.1189757 ,  0.09042569,  0.19359394,  0.10031318,\n",
       "        0.10050775,  0.0857817 ,  0.07507654,  0.11047341,  0.12546144,\n",
       "        0.04875977,  0.09053747,  0.08108097,  0.08994445,  0.09708038,\n",
       "        0.07938167,  0.1119983 ,  0.08092808,  0.05809116,  0.11701868,\n",
       "        0.09319509,  0.085043  ,  0.06840172,  0.10580203,  0.07417088,\n",
       "        0.09094252,  0.09667842,  0.11157618,  0.07360414,  0.14344233,\n",
       "        0.1252882 ,  0.09791359,  0.06366372,  0.05287163,  0.07764433,\n",
       "        0.09060281,  0.13007454,  0.11351586,  0.07844685,  0.10701501,\n",
       "        0.10364875,  0.06907587,  0.10595871,  0.0943535 ,  0.05276092,\n",
       "        0.07984162,  0.04734774,  0.07542471,  0.1244544 ,  0.16146949,\n",
       "        0.16363215,  0.08200292,  0.10862592,  0.09040995,  0.11740204,\n",
       "        0.08222421,  0.11428935,  0.15889903,  0.09074808,  0.09740625,\n",
       "        0.08848291,  0.13383783,  0.07698761,  0.10871651,  0.09483882,\n",
       "        0.11073238,  0.10040586,  0.08842418,  0.11137499,  0.13667154,\n",
       "        0.10592708,  0.09705796,  0.10325613,  0.06915902,  0.09832974,\n",
       "        0.08807648,  0.06387629,  0.08388523,  0.13561435,  0.09085258,\n",
       "        0.07118831,  0.08774445,  0.12365124,  0.10196318,  0.08183947,\n",
       "        0.09588465,  0.05490965,  0.10122207,  0.12279973,  0.10479258,\n",
       "        0.11389383,  0.10722561,  0.0891783 ,  0.10523945,  0.04686361,\n",
       "        0.11733254,  0.08435048,  0.12009475,  0.10694563,  0.11007867,\n",
       "        0.06683872,  0.0625841 ,  0.07919051,  0.19704189,  0.05046557,\n",
       "        0.11899767,  0.09108826,  0.05309074,  0.09133658,  0.13557631,\n",
       "        0.0647283 ,  0.09714596,  0.0933572 ,  0.07303074,  0.09042012,\n",
       "        0.11442084,  0.13112084,  0.10524911,  0.09460816,  0.11042307,\n",
       "        0.11418003,  0.08719759,  0.08728316,  0.06672831,  0.1481374 ,\n",
       "        0.07639991,  0.12586954,  0.05772746,  0.06115179,  0.09909684,\n",
       "        0.08784664,  0.13667415,  0.19386489,  0.07696437,  0.08208363,\n",
       "        0.07566602,  0.06498412,  0.09071696,  0.10669894,  0.09187564,\n",
       "        0.16470244,  0.06474611,  0.14396954,  0.09490431,  0.08478602,\n",
       "        0.11040844,  0.06152753,  0.07731284,  0.11607742,  0.10374097,\n",
       "        0.12985343,  0.05630317,  0.11579191,  0.10256309,  0.10176666])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = np.divide(scores, scores_sums.reshape(num_train,1))\n",
    "print (s)\n",
    "print (s.shape)\n",
    "s[range(num_train), y_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grad\n",
    "  s = np.divide(scores, scores_sums.reshape(num_train,1))\n",
    "  s[range(num_train), y] =- (scores_sums - cors) / scores_sums\n",
    "  dW = X.T.dot(s)\n",
    "  dW /= num_train\n",
    "  dW += 2 * reg * W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " scores -= scores.max()\n",
    "  scores = np.exp(scores)\n",
    "  scores_sums = np.sum(scores, axis=1)\n",
    "  cors = scores[range(num_train), y]\n",
    "  loss = cors / scores_sums\n",
    "  loss = -np.sum(np.log(loss))/num_train + reg * np.sum(W*W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_loss_vectorized(W, X, y, reg):\n",
    "  \"\"\"\n",
    "  Softmax loss function, vectorized version.\n",
    "\n",
    "  Inputs and outputs are the same as softmax_loss_naive.\n",
    "  \"\"\"\n",
    "  # Initialize the loss and gradient to zero.\n",
    "  loss = 0.0\n",
    "  dW = np.zeros_like(W)\n",
    "  num_classes = W.shape[1]\n",
    "  num_train = X.shape[0]\n",
    "\n",
    "  #############################################################################\n",
    "  # TODO: Compute the softmax loss and its gradient using no explicit loops.  #\n",
    "  # Store the loss in loss and the gradient in dW. If you are not careful     #\n",
    "  # here, it is easy to run into numeric instability. Don't forget the        #\n",
    "  # regularization!                                                           #\n",
    "  #############################################################################\n",
    "  scores = X.dot(W)\n",
    "  scores -= scores.max()\n",
    "  scores = np.exp(scores)\n",
    "  scores_sums = np.sum(scores, axis=1)\n",
    "  cors = scores[range(num_train), y]\n",
    "  loss = cors / scores_sums\n",
    "  loss = -np.sum(np.log(loss))/num_train + reg * np.sum(W*W)\n",
    "\n",
    "  # grad\n",
    "  s = np.divide(scores, scores_sums.reshape(num_train,1))\n",
    "  s[range(num_train), y] =- (scores_sums - cors) / scores_sums\n",
    "  dW = X.T.dot(s)\n",
    "  dW /= num_train\n",
    "  dW += 2 * reg * W\n",
    "  #############################################################################\n",
    "  #                          END OF YOUR CODE                                 #\n",
    "  #############################################################################\n",
    "\n",
    "  return loss, dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.330796 val accuracy: 0.342000\n",
      "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.312265 val accuracy: 0.328000\n",
      "lr 5.000000e-07 reg 2.500000e+04 train accuracy: 0.322490 val accuracy: 0.338000\n",
      "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.302061 val accuracy: 0.316000\n",
      "best validation accuracy achieved during cross-validation: 0.342000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-7, 5e-7]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "softmax = Softmax()\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in regularization_strengths:\n",
    "        loss_hist = softmax.train(X_train, y_train, learning_rate=lr, reg=reg, num_iters=1500)\n",
    "        \n",
    "        y_train_pred = softmax.predict(X_train)\n",
    "        acc_train = np.mean(y_train == y_train_pred)\n",
    "        \n",
    "        y_val_pred = softmax.predict(X_val)\n",
    "        acc_val = np.mean(y_val == y_val_pred)\n",
    "        \n",
    "        results[(lr, reg)] = (acc_train, acc_val)\n",
    "        \n",
    "        if acc_val > best_val:\n",
    "            best_val = acc_val\n",
    "            best_softmax = softmax\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.312000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAF8CAYAAADrUz6WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11077ebe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
